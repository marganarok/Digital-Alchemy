<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KAI Gaming Assistant - Sons of the Forest Implementation</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    
    <style>
        :root {
            --forest-dark: #1a2e1a;
            --forest-green: #2d5016;
            --leaf-green: #4a7c59;
            --survival-orange: #d97706;
            --danger-red: #dc2626;
            --tool-gray: #6b7280;
            --light-green: #dcfce7;
            --dark-bg: #0f172a;
            --code-bg: #1e293b;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, var(--dark-bg) 0%, var(--forest-dark) 100%);
            color: #e2e8f0;
            line-height: 1.6;
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        .header {
            background: linear-gradient(135deg, var(--forest-green), var(--leaf-green));
            padding: 60px 0;
            text-align: center;
            border-bottom: 3px solid var(--survival-orange);
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 700;
            color: white;
            margin-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2rem;
            color: var(--light-green);
            max-width: 600px;
            margin: 0 auto;
        }

        .nav {
            background: var(--forest-dark);
            padding: 20px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            border-bottom: 1px solid var(--leaf-green);
        }

        .nav-links {
            display: flex;
            justify-content: center;
            gap: 30px;
            flex-wrap: wrap;
        }

        .nav-link {
            color: #cbd5e1;
            text-decoration: none;
            padding: 10px 20px;
            border-radius: 25px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .nav-link:hover, .nav-link.active {
            background: var(--survival-orange);
            color: white;
            transform: translateY(-2px);
        }

        .section {
            margin: 60px 0;
        }

        .section-title {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--survival-orange);
            margin-bottom: 30px;
            text-align: center;
        }

        .card {
            background: rgba(30, 41, 59, 0.9);
            border: 1px solid var(--leaf-green);
            border-radius: 15px;
            padding: 30px;
            margin-bottom: 30px;
            backdrop-filter: blur(10px);
        }

        .card h3 {
            color: var(--survival-orange);
            font-size: 1.5rem;
            margin-bottom: 20px;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 30px 0;
        }

        .phase-card {
            background: linear-gradient(135deg, var(--forest-green), var(--leaf-green));
            border: 2px solid var(--survival-orange);
            border-radius: 15px;
            padding: 25px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .phase-number {
            position: absolute;
            top: -20px;
            right: -20px;
            width: 80px;
            height: 80px;
            background: var(--survival-orange);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2rem;
            font-weight: bold;
            color: white;
        }

        .phase-title {
            font-size: 1.3rem;
            font-weight: 600;
            color: white;
            margin-bottom: 15px;
            margin-top: 20px;
        }

        .phase-subtitle {
            color: var(--light-green);
            font-style: italic;
            margin-bottom: 20px;
        }

        .code-block {
            background: var(--code-bg);
            color: #e2e8f0;
            padding: 20px;
            border-radius: 10px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
            margin: 20px 0;
            border-left: 4px solid var(--survival-orange);
        }

        .feature-list {
            list-style: none;
            margin: 20px 0;
        }

        .feature-list li {
            padding: 10px 0;
            position: relative;
            padding-left: 30px;
            color: #cbd5e1;
        }

        .feature-list li::before {
            content: '🎯';
            position: absolute;
            left: 0;
            top: 10px;
        }

        .warning-box {
            background: rgba(220, 38, 38, 0.1);
            border: 2px solid var(--danger-red);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }

        .warning-box h4 {
            color: var(--danger-red);
            margin-bottom: 10px;
        }

        .info-box {
            background: rgba(77, 124, 89, 0.1);
            border: 2px solid var(--leaf-green);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }

        .info-box h4 {
            color: var(--leaf-green);
            margin-bottom: 10px;
        }

        .implementation-timeline {
            background: var(--forest-dark);
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
        }

        .timeline-item {
            display: flex;
            margin-bottom: 30px;
            position: relative;
        }

        .timeline-marker {
            width: 40px;
            height: 40px;
            background: var(--survival-orange);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            margin-right: 20px;
            flex-shrink: 0;
        }

        .timeline-content {
            flex: 1;
        }

        .timeline-content h4 {
            color: var(--survival-orange);
            margin-bottom: 10px;
        }

        .btn {
            display: inline-block;
            padding: 12px 24px;
            background: var(--survival-orange);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 500;
            transition: all 0.3s ease;
            margin: 10px 5px;
            border: none;
            cursor: pointer;
        }

        .btn:hover {
            background: #ea580c;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(217, 119, 6, 0.3);
        }

        .btn-secondary {
            background: var(--tool-gray);
        }

        .btn-secondary:hover {
            background: #4b5563;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .nav-links {
                flex-direction: column;
                align-items: center;
                gap: 10px;
            }
            
            .grid {
                grid-template-columns: 1fr;
            }
            
            .timeline-item {
                flex-direction: column;
                text-align: center;
            }
            
            .timeline-marker {
                margin: 0 auto 15px auto;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <h1>🎮 KAI Gaming Assistant</h1>
            <p>AI-Powered Survival Companion for Sons of the Forest</p>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="nav">
        <div class="container">
            <div class="nav-links">
                <a href="#overview" class="nav-link active">Overview</a>
                <a href="#architecture" class="nav-link">Architecture</a>
                <a href="#implementation" class="nav-link">Implementation</a>
                <a href="#features" class="nav-link">Game Features</a>
                <a href="#deployment" class="nav-link">Deployment</a>
            </div>
        </div>
    </nav>

    <main class="container">
        <!-- Overview -->
        <section id="overview" class="section">
            <h2 class="section-title">Project Overview</h2>
            
            <div class="info-box">
                <h4>🎯 Mission Objective</h4>
                <p>Transform your LocalAI Assistant into an intelligent gaming companion that can understand natural language commands, see the game world, and execute survival strategies in Sons of the Forest through voice commands and AI decision-making.</p>
            </div>

            <div class="grid">
                <div class="phase-card">
                    <div class="phase-number">1</div>
                    <div class="phase-title">The Soul (Brain)</div>
                    <div class="phase-subtitle">Enhanced LocalAI Core</div>
                    <p>Extend your existing LocalAI Assistant with game-specific command parsing and tactical decision-making capabilities.</p>
                </div>

                <div class="phase-card">
                    <div class="phase-number">2</div>
                    <div class="phase-title">The Voice & Ears</div>
                    <div class="phase-subtitle">Speech Interface</div>
                    <p>Real-time speech recognition that listens for survival commands and responds with voice feedback.</p>
                </div>

                <div class="phase-card">
                    <div class="phase-number">3</div>
                    <div class="phase-title">The Hands</div>
                    <div class="phase-subtitle">Game Controller</div>
                    <p>Automated input simulation that can move, interact, and perform survival actions in the game world.</p>
                </div>

                <div class="phase-card">
                    <div class="phase-number">4</div>
                    <div class="phase-title">The Eyes</div>
                    <div class="phase-subtitle">Computer Vision</div>
                    <p>Real-time game analysis that recognizes resources, threats, terrain, and survival opportunities.</p>
                </div>
            </div>

            <div class="warning-box">
                <h4>⚠️ Important Considerations</h4>
                <ul>
                    <li><strong>Single-Player Only:</strong> This system is designed exclusively for single-player experiences</li>
                    <li><strong>Performance Impact:</strong> Real-time CV and AI processing will affect game performance</li>
                    <li><strong>Game Updates:</strong> Vision models may need retraining when game UI changes</li>
                    <li><strong>Hardware Requirements:</strong> Requires decent GPU for simultaneous game + AI processing</li>
                </ul>
            </div>
        </section>

        <!-- Architecture -->
        <section id="architecture" class="section">
            <h2 class="section-title">Technical Architecture</h2>

            <div class="card">
                <h3>System Components Integration</h3>
                
                <div class="code-block">
# Extended LocalAI Assistant Architecture
LocalAI-Gaming-Assistant/
├── src/
│   ├── core/                    # Original LocalAI core
│   ├── gaming/                  # New gaming extension
│   │   ├── brain/              # Command parsing & decision logic
│   │   ├── vision/             # Computer vision module
│   │   ├── voice/              # Speech recognition & TTS
│   │   ├── controller/         # Input simulation
│   │   └── games/              # Game-specific implementations
│   │       └── sons_of_forest/ # SotF specific logic
├── models/
│   ├── game_vision/            # Trained CV models
│   ├── command_parsing/        # NLP models for commands
│   └── speech/                 # Voice models
└── config/
    └── sons_of_forest.yaml     # Game-specific configuration
                </div>

                <h4>Core Architecture Principles:</h4>
                <ul class="feature-list">
                    <li><strong>Modular Design:</strong> Each phase operates independently with clean interfaces</li>
                    <li><strong>Real-time Processing:</strong> Low-latency command execution for responsive gameplay</li>
                    <li><strong>Extensible Framework:</strong> Easy to add support for other survival games</li>
                    <li><strong>Safety First:</strong> Built-in safeguards to prevent dangerous actions</li>
                </ul>
            </div>

            <div class="card">
                <h3>Data Flow Architecture</h3>
                
                <div class="implementation-timeline">
                    <div class="timeline-item">
                        <div class="timeline-marker">👂</div>
                        <div class="timeline-content">
                            <h4>Voice Input Capture</h4>
                            <p>Continuous listening for wake word "Hey KAI" → Speech-to-text conversion → Command parsing</p>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">🧠</div>
                        <div class="timeline-content">
                            <h4>AI Decision Processing</h4>
                            <p>Natural language → Structured command → Game context analysis → Action planning</p>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">👁️</div>
                        <div class="timeline-content">
                            <h4>Visual Analysis</h4>
                            <p>Screenshot capture → Object detection → Game state analysis → Tactical assessment</p>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">🎮</div>
                        <div class="timeline-content">
                            <h4>Action Execution</h4>
                            <p>Action sequence planning → Input simulation → Feedback monitoring → Result verification</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Implementation -->
        <section id="implementation" class="section">
            <h2 class="section-title">Phase-by-Phase Implementation</h2>

            <div class="card">
                <h3>Phase 1: The Soul (Enhanced Brain)</h3>
                
                <div class="code-block">
# src/gaming/brain/survival_commander.py
class SurvivalCommander:
    def __init__(self, base_llm):
        self.llm = base_llm
        self.game_state = GameState()
        self.command_parser = CommandParser()
        
    def process_voice_command(self, speech_text: str) -> ActionPlan:
        """Convert natural language to game actions"""
        
        # Parse intent from speech
        intent = self.command_parser.parse(speech_text)
        
        # Examples of command mapping:
        commands = {
            "go there": self.create_movement_plan,
            "build shelter": self.create_building_plan,
            "find food": self.create_foraging_plan,
            "avoid danger": self.create_evasion_plan,
            "help kelvin": self.create_companion_help_plan
        }
        
        if intent.command in commands:
            return commands[intent.command](intent.parameters)
        else:
            return self.llm_fallback_planning(speech_text)
    
    def create_movement_plan(self, target_location):
        """Plan safe movement to target"""
        current_pos = self.game_state.player_position
        path = self.pathfinding.find_safe_route(current_pos, target_location)
        return ActionPlan([
            MoveAction(waypoint) for waypoint in path
        ])
</div>

                <h4>Key Features:</h4>
                <ul class="feature-list">
                    <li>Natural language command interpretation</li>
                    <li>Context-aware decision making</li>
                    <li>Safety-first action planning</li>
                    <li>Integration with existing LocalAI personality</li>
                </ul>
            </div>

            <div class="card">
                <h3>Phase 2: Voice & Ears (Speech Interface)</h3>
                
                <div class="code-block">
# src/gaming/voice/speech_interface.py
import speech_recognition as sr
import pyttsx3
import pyaudio
from threading import Thread
import queue

class SpeechInterface:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.tts_engine = pyttsx3.init()
        self.command_queue = queue.Queue()
        self.listening = False
        
    def start_listening(self):
        """Start continuous listening for wake word and commands"""
        self.listening = True
        Thread(target=self._listen_loop, daemon=True).start()
        
    def _listen_loop(self):
        """Main listening loop with wake word detection"""
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source)
            
        while self.listening:
            try:
                # Listen for wake word "Hey KAI"
                audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=5)
                speech = self.recognizer.recognize_google(audio)
                
                if "hey kai" in speech.lower():
                    self.speak("Yes? What do you need?")
                    command_audio = self.recognizer.listen(source, timeout=5)
                    command = self.recognizer.recognize_google(command_audio)
                    self.command_queue.put(command)
                    
            except sr.WaitTimeoutError:
                continue
            except sr.UnknownValueError:
                continue
                
    def speak(self, text: str):
        """Convert text to speech"""
        self.tts_engine.say(text)
        self.tts_engine.runAndWait()
        
    def get_command(self) -> str:
        """Get next command from queue"""
        if not self.command_queue.empty():
            return self.command_queue.get()
        return None
</div>

                <h4>Speech Features:</h4>
                <ul class="feature-list">
                    <li>Wake word activation ("Hey KAI")</li>
                    <li>Noise filtering for gaming environments</li>
                    <li>Voice feedback and confirmations</li>
                    <li>Offline speech recognition option</li>
                </ul>
            </div>

            <div class="card">
                <h3>Phase 3: The Hands (Game Controller)</h3>
                
                <div class="code-block">
# src/gaming/controller/game_input.py
import pyautogui
import time
import numpy as np
from dataclasses import dataclass

@dataclass
class GameAction:
    action_type: str  # 'move', 'click', 'key', 'sequence'
    parameters: dict
    duration: float = 0.1

class SonsOfForestController:
    def __init__(self):
        # Sons of the Forest key bindings
        self.key_bindings = {
            'move_forward': 'w',
            'move_backward': 's', 
            'move_left': 'a',
            'move_right': 'd',
            'run': 'shift',
            'crouch': 'ctrl',
            'jump': 'space',
            'interact': 'e',
            'inventory': 'i',
            'build': 'b',
            'chop': 'left_click',
            'attack': 'left_click'
        }
        
        # Disable pyautogui failsafe for gaming
        pyautogui.FAILSAFE = False
        pyautogui.PAUSE = 0.01  # Minimal delay for responsiveness
        
    def execute_action(self, action: GameAction):
        """Execute a game action safely"""
        try:
            if action.action_type == 'move':
                self._move_character(action.parameters)
            elif action.action_type == 'interact':
                self._interact_with_object(action.parameters)
            elif action.action_type == 'build':
                self._build_structure(action.parameters)
                
        except Exception as e:
            print(f"Action execution failed: {e}")
            
    def _move_character(self, params):
        """Move character in specified direction"""
        direction = params.get('direction', 'forward')
        duration = params.get('duration', 1.0)
        
        key = self.key_bindings.get(f'move_{direction}', 'w')
        
        # Hold key for specified duration
        pyautogui.keyDown(key)
        time.sleep(duration)
        pyautogui.keyUp(key)
        
    def _interact_with_object(self, params):
        """Interact with objects in the game world"""
        screen_pos = params.get('screen_position')
        
        if screen_pos:
            # Click on the object
            pyautogui.click(screen_pos[0], screen_pos[1])
            time.sleep(0.5)
            # Press interact key
            pyautogui.press(self.key_bindings['interact'])
            
    def move_to_coordinates(self, target_x, target_y, current_x, current_y):
        """Calculate and execute movement to target coordinates"""
        # Calculate direction vector
        dx = target_x - current_x
        dy = target_y - current_y
        distance = np.sqrt(dx**2 + dy**2)
        
        if distance > 10:  # Minimum movement threshold
            # Normalize direction
            dx_norm = dx / distance
            dy_norm = dy / distance
            
            # Convert to key presses
            move_time = min(distance / 100, 5.0)  # Max 5 seconds
            
            # Execute movement
            if abs(dx_norm) > abs(dy_norm):
                key = 'd' if dx_norm > 0 else 'a'
            else:
                key = 'w' if dy_norm > 0 else 's'
                
            pyautogui.keyDown(key)
            time.sleep(move_time)
            pyautogui.keyUp(key)
</div>

                <h4>Controller Features:</h4>
                <ul class="feature-list">
                    <li>Safe input simulation with error handling</li>
                    <li>Natural movement patterns to avoid detection</li>
                    <li>Customizable key bindings per game</li>
                    <li>Complex action sequences (build, gather, fight)</li>
                </ul>
            </div>

            <div class="card">
                <h3>Phase 4: The Eyes (Computer Vision)</h3>
                
                <div class="code-block">
# src/gaming/vision/game_vision.py
import cv2
import numpy as np
import mss
from ultralytics import YOLO
import pytesseract

class SonsOfForestVision:
    def __init__(self):
        # Load pre-trained YOLO model for object detection
        self.object_detector = YOLO('yolov8n.pt')
        
        # Custom model for game-specific objects (train separately)
        self.game_detector = None  # Load after training
        
        # Screen capture setup
        self.sct = mss.mss()
        self.game_window = self._find_game_window()
        
        # Game-specific templates for template matching
        self.ui_templates = self._load_ui_templates()
        
    def analyze_game_state(self) -> dict:
        """Analyze current game state from screenshot"""
        screenshot = self.capture_game_screen()
        
        analysis = {
            'player_stats': self._detect_player_stats(screenshot),
            'environment': self._analyze_environment(screenshot),
            'objects': self._detect_objects(screenshot),
            'threats': self._detect_threats(screenshot),
            'resources': self._detect_resources(screenshot),
            'ui_state': self._analyze_ui(screenshot)
        }
        
        return analysis
        
    def capture_game_screen(self) -> np.ndarray:
        """Capture screenshot of game window"""
        monitor = self.game_window
        screenshot = self.sct.grab(monitor)
        return np.array(screenshot)
        
    def _detect_player_stats(self, image) -> dict:
        """Extract player health, hunger, thirst from UI"""
        # Use template matching for UI elements
        health_bar = self._find_template(image, self.ui_templates['health_bar'])
        hunger_bar = self._find_template(image, self.ui_templates['hunger_bar'])
        
        return {
            'health': self._extract_bar_percentage(health_bar),
            'hunger': self._extract_bar_percentage(hunger_bar),
            'thirst': self._extract_bar_percentage(self._find_template(image, self.ui_templates['thirst_bar']))
        }
        
    def _detect_objects(self, image) -> list:
        """Detect interactable objects in the game world"""
        # Use YOLO for general object detection
        results = self.object_detector(image)
        
        objects = []
        for result in results:
            for box in result.boxes:
                if box.conf > 0.5:  # Confidence threshold
                    objects.append({
                        'type': result.names[int(box.cls)],
                        'confidence': float(box.conf),
                        'bbox': box.xyxy[0].tolist(),
                        'center': self._calculate_center(box.xyxy[0])
                    })
                    
        return objects
        
    def _detect_threats(self, image) -> list:
        """Detect enemies, dangerous animals, hazards"""
        # Look for movement, red indicators, enemy shapes
        threats = []
        
        # Convert to HSV for better color detection
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Detect red enemy indicators
        red_mask = cv2.inRange(hsv, (0, 50, 50), (10, 255, 255))
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            if cv2.contourArea(contour) > 100:  # Minimum size
                x, y, w, h = cv2.boundingRect(contour)
                threats.append({
                    'type': 'unknown_threat',
                    'position': (x + w//2, y + h//2),
                    'size': cv2.contourArea(contour)
                })
                
        return threats
        
    def _detect_resources(self, image) -> list:
        """Detect collectible resources like sticks, rocks, berries"""
        resources = []
        
        # Use color-based detection for different resource types
        resource_colors = {
            'sticks': [(10, 50, 20), (20, 255, 200)],    # Brown ranges
            'rocks': [(80, 50, 50), (100, 255, 200)],    # Gray ranges  
            'berries': [(160, 50, 50), (180, 255, 255)]  # Red ranges
        }
        
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        for resource_type, (lower, upper) in resource_colors.items():
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                if 50 < cv2.contourArea(contour) < 5000:  # Size filtering
                    x, y, w, h = cv2.boundingRect(contour)
                    resources.append({
                        'type': resource_type,
                        'position': (x + w//2, y + h//2),
                        'confidence': 0.7  # Color-based detection confidence
                    })
                    
        return resources
        
    def find_safe_path(self, start_pos, target_pos, obstacles) -> list:
        """Calculate safe path avoiding threats and obstacles"""
        # Simple A* pathfinding implementation
        # This would be expanded for proper navigation
        return [start_pos, target_pos]  # Simplified for example
</div>

                <h4>Vision Capabilities:</h4>
                <ul class="feature-list">
                    <li>Real-time object detection (trees, rocks, enemies)</li>
                    <li>UI element recognition (health, hunger, inventory)</li>
                    <li>Threat detection and avoidance</li>
                    <li>Resource identification and mapping</li>
                    <li>Pathfinding with obstacle avoidance</li>
                </ul>
            </div>
        </section>

        <!-- Game Features -->
        <section id="features" class="section">
            <h2 class="section-title">Sons of the Forest AI Features</h2>

            <div class="grid">
                <div class="card">
                    <h3>Survival Commands</h3>
                    <div class="code-block">
# Voice Commands KAI Understands:

"Hey KAI, find me some food"
→ Scans for berries, hunts small game, identifies edible plants

"Build a shelter near the water"  
→ Finds suitable location, gathers materials, constructs basic shelter

"Kelvin needs help with the logs"
→ Directs companion AI, coordinates building tasks

"Danger! Get us out of here!"
→ Emergency evasion, finds safe route, prioritizes survival

"What's our status?"
→ Reports health, resources, current objectives

"Set up camp for the night"
→ Builds fire, sets up sleeping area, defensive positioning
                    </div>
                    
                    <h4>Supported Survival Actions:</h4>
                    <ul class="feature-list">
                        <li>Resource gathering automation</li>
                        <li>Base building assistance</li>
                        <li>Companion management</li>
                        <li>Threat avoidance</li>
                        <li>Day/night cycle planning</li>
                    </ul>
                </div>

                <div class="card">
                    <h3>Environmental Awareness</h3>
                    
                    <div class="code-block">
class EnvironmentAnalyzer:
    def assess_survival_situation(self, vision_data):
        """Analyze current survival priorities"""
        
        priorities = []
        
        # Check basic needs
        if vision_data['player_stats']['health'] < 30:
            priorities.append(('health', 'CRITICAL'))
        if vision_data['player_stats']['hunger'] < 20:
            priorities.append(('food', 'URGENT'))
        if vision_data['player_stats']['thirst'] < 15:
            priorities.append(('water', 'URGENT'))
            
        # Environmental threats
        if len(vision_data['threats']) > 0:
            priorities.append(('safety', 'IMMEDIATE'))
            
        # Weather and time
        if self.is_night_approaching():
            priorities.append(('shelter', 'IMPORTANT'))
            
        return self.rank_priorities(priorities)
</div>

                    <h4>AI Decision Making:</h4>
                    <ul class="feature-list">
                        <li>Contextual priority assessment</li>
                        <li>Weather and time awareness</li>
                        <li>Resource optimization</li>
                        <li>Risk evaluation</li>
                        <li>Long-term planning</li>
                    </ul>
                </div>

                <div class="card">
                    <h3>Combat & Defense</h3>
                    
                    <div class="code-block">
# Combat scenarios KAI handles:

"Cannibals approaching from the north!"
→ Analyzes threat level, chooses fight/flight/hide
→ Coordinates with Kelvin for group tactics
→ Uses terrain advantages

"Build defenses around our base"
→ Identifies vulnerable approaches
→ Plans spike walls and traps
→ Optimizes defensive positioning

"Something's stalking us"
→ Enters stealth mode
→ Scans for threats using enhanced vision
→ Plans escape routes
</div>

                    <h4>Defense Capabilities:</h4>
                    <ul class="feature-list">
                        <li>Threat level assessment</li>
                        <li>Tactical retreat planning</li>
                        <li>Defensive structure construction</li>
                        <li>Group coordination</li>
                        <li>Stealth movement</li>
                    </ul>
                </div>
            </div>

            <div class="info-box">
                <h4>Adaptive Learning System</h4>
                <p>KAI learns from each playthrough, building knowledge about optimal survival strategies, resource locations, and threat patterns specific to your playstyle and the game world.</p>
            </div>
        </section>

        <!-- Deployment -->
        <section id="deployment" class="section">
            <h2 class="section-title">Deployment & Setup</h2>

            <div class="card">
                <h3>Hardware Requirements</h3>
                
                <div class="grid">
                    <div style="background: rgba(77, 124, 89, 0.1); padding: 20px; border-radius: 10px;">
                        <h4>Minimum Specs</h4>
                        <ul class="feature-list">
                            <li>GTX 1060 / RTX 2060</li>
                            <li>16GB RAM</li>
                            <li>Intel i5-8400 / AMD Ryzen 5 2600</li>
                            <li>Dedicated microphone</li>
                            <li>1080p display</li>
                        </ul>
                    </div>
                    
                    <div style="background: rgba(217, 119, 6, 0.1); padding: 20px; border-radius: 10px;">
                        <h4>Recommended Specs</h4>
                        <ul class="feature-list">
                            <li>RTX 3070+ / RTX 4060+</li>
                            <li>32GB RAM</li>
                            <li>Intel i7-10700K+ / AMD Ryzen 7 3700X+</li>
                            <li>High-quality gaming headset</li>
                            <li>1440p+ display</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="card">
                <h3>Installation Process</h3>
                
                <div class="implementation-timeline">
                    <div class="timeline-item">
                        <div class="timeline-marker">1</div>
                        <div class="timeline-content">
                            <h4>Base System Setup</h4>
                            <div class="code-block">
# Clone the enhanced LocalAI Assistant
git clone https://github.com/your-repo/LocalAI-Gaming-Assistant
cd LocalAI-Gaming-Assistant

# Install Python dependencies
pip install -r requirements.txt

# Install additional gaming dependencies
pip install pyautogui opencv-python ultralytics
pip install speech-recognition pyttsx3 pyaudio
pip install mss pytesseract pillow
                            </div>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">2</div>
                        <div class="timeline-content">
                            <h4>Model Downloads</h4>
                            <div class="code-block">
# Download base vision models
python scripts/download_models.py --game sons_of_forest

# This downloads:
# - YOLOv8 for object detection
# - Custom SotF UI recognition models
# - Speech recognition models
# - Enhanced LocalAI gaming personality
                            </div>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">3</div>
                        <div class="timeline-content">
                            <h4>Game Integration</h4>
                            <div class="code-block">
# Configure for Sons of the Forest
python setup_game.py --game "Sons of the Forest"

# Calibrate screen capture region
python calibrate_vision.py

# Test voice recognition
python test_speech.py

# Run initial training on your gameplay
python train_custom_vision.py --hours 2
                            </div>
                        </div>
                    </div>
                    
                    <div class="timeline-item">
                        <div class="timeline-marker">4</div>
                        <div class="timeline-content">
                            <h4>Launch KAI Assistant</h4>
                            <div class="code-block">
# Start the gaming assistant
python main.py --mode gaming --game sons_of_forest

# KAI will:
# 1. Load gaming personality
# 2. Initialize vision system
# 3. Start voice listening
# 4. Connect to game window
# 5. Begin survival assistance
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="card">
                <h3>Configuration & Customization</h3>
                
                <div class="code-block">
# config/sons_of_forest.yaml
game_settings:
  window_title: "Sons Of The Forest"
  capture_fps: 10
  response_delay_ms: 100
  
voice_settings:
  wake_word: "hey kai"
  confidence_threshold: 0.7
  noise_suppression: true
  
ai_personality:
  survival_focus: 0.8
  risk_aversion: 0.6
  resource_efficiency: 0.9
  companion_cooperation: 0.7
  
vision_settings:
  object_detection_confidence: 0.5
  ui_recognition_confidence: 0.8
  threat_sensitivity: 0.7
  
input_settings:
  movement_smoothing: true
  action_confirmation: false
  emergency_stop_key: "f12"
</div>

                <h4>Customization Options:</h4>
                <ul class="feature-list">
                    <li>Adjust AI aggression and risk tolerance</li>
                    <li>Customize voice commands and responses</li>
                    <li>Tune vision sensitivity for your display</li>
                    <li>Set personal survival priorities</li>
                    <li>Configure companion interaction style</li>
                </ul>
            </div>

            <div class="warning-box">
                <h4>Performance Considerations</h4>
                <ul>
                    <li><strong>FPS Impact:</strong> Expect 10-20% frame rate reduction during active AI processing</li>
                    <li><strong>Memory Usage:</strong> Additional 4-8GB RAM usage for AI models</li>
                    <li><strong>CPU Load:</strong> Continuous background processing for vision and speech</li>
                    <li><strong>Disk Space:</strong> 10-15GB for all models and training data</li>
                </ul>
            </div>

            <div class="card">
                <h3>Training Your Custom Models</h3>
                
                <div class="code-block">
# Train KAI on your specific gameplay style
class CustomTrainingPipeline:
    def train_on_gameplay(self, hours_of_footage):
        """Train vision models on your Sons of Forest gameplay"""
        
        # Record gameplay sessions
        recordings = self.capture_gameplay_footage(hours_of_footage)
        
        # Extract training data
        training_data = []
        for recording in recordings:
            frames = self.extract_frames(recording)
            annotations = self.auto_annotate_objects(frames)
            training_data.extend(zip(frames, annotations))
        
        # Fine-tune object detection
        self.fine_tune_yolo(training_data)
        
        # Train UI element recognition
        ui_data = self.extract_ui_elements(recordings)
        self.train_ui_classifier(ui_data)
        
        # Learn player behavior patterns
        actions = self.extract_player_actions(recordings)
        self.update_decision_trees(actions)
        
    def continuous_learning(self):
        """Learn from ongoing gameplay"""
        while self.is_active:
            screenshot = self.capture_screen()
            actions = self.get_recent_actions()
            
            # Evaluate action success
            success_score = self.evaluate_action_outcome(actions, screenshot)
            
            # Update models based on success
            if success_score > 0.8:
                self.reinforce_successful_patterns(actions)
            elif success_score < 0.3:
                self.learn_from_failures(actions)
</div>

                <h4>Training Benefits:</h4>
                <ul class="feature-list">
                    <li>Adapts to your specific survival strategies</li>
                    <li>Learns optimal resource locations in your world</li>
                    <li>Recognizes your preferred building techniques</li>
                    <li>Improves threat response based on your playstyle</li>
                    <li>Develops personalized survival priorities</li>
                </ul>
            </div>
        </section>

        <!-- Final Section -->
        <section class="section">
            <div class="card" style="text-align: center; background: linear-gradient(135deg, var(--forest-green), var(--leaf-green)); color: white; border: 3px solid var(--survival-orange);">
                <h2>Deploy Your AI Survival Companion</h2>
                <p style="font-size: 1.2rem; margin: 20px 0;">Transform your LocalAI Assistant into the ultimate survival gaming companion. KAI will watch, learn, and help you thrive in the dangerous world of Sons of the Forest.</p>
                
                <div style="margin: 30px 0;">
                    <button class="btn" style="background: var(--survival-orange); font-size: 1.1rem; padding: 15px 30px;">Download KAI Gaming Extension</button>
                    <button class="btn btn-secondary" style="margin-left: 15px;">View Documentation</button>
                </div>
                
                <div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 10px; margin: 20px 0;">
                    <h4>Ready to Survive with AI?</h4>
                    <p>Hey KAI, let's build the ultimate forest base!</p>
                </div>
                
                <p style="opacity: 0.9; margin-top: 20px;">
                    <em>Your AI companion that sees, thinks, and acts - making survival gaming more strategic and engaging than ever.</em>
                </p>
            </div>
        </section>
    </main>

    <script>
        // Navigation functionality
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const targetId = this.getAttribute('href').substring(1);
                const targetElement = document.getElementById(targetId);
                
                if (targetElement) {
                    const offsetTop = targetElement.getBoundingClientRect().top + window.pageYOffset - 80;
                    window.scrollTo({
                        top: offsetTop,
                        behavior: 'smooth'
                    });
                    
                    document.querySelectorAll('.nav-link').forEach(nav => nav.classList.remove('active'));
                    this.classList.add('active');
                }
            });
        });

        // Update active nav on scroll
        window.addEventListener('scroll', function() {
            const sections = document.querySelectorAll('section[id]');
            const navLinks = document.querySelectorAll('.nav-link');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.getBoundingClientRect().top;
                if (sectionTop <= 100) {
                    current = section.getAttribute('id');
                }
            });
            
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href').substring(1) === current) {
                    link.classList.add('active');
                }
            });
        });

        // Smooth hover effects
        document.querySelectorAll('.card, .phase-card').forEach(card => {
            card.addEventListener('mouseenter', function() {
                this.style.transform = 'translateY(-5px)';
                this.style.transition = 'all 0.3s ease';
            });
            
            card.addEventListener('mouseleave', function() {
                this.style.transform = 'translateY(0)';
            });
        });

        // Add some fun interactive elements
        document.querySelectorAll('.btn').forEach(btn => {
            btn.addEventListener('click', function(e) {
                if (!this.href || this.href === '#') {
                    e.preventDefault();
                    
                    // Create a fun notification
                    const notification = document.createElement('div');
                    notification.textContent = 'KAI Gaming Assistant coming soon!';
                    notification.style.cssText = `
                        position: fixed;
                        top: 20px;
                        right: 20px;
                        background: var(--survival-orange);
                        color: white;
                        padding: 15px 25px;
                        border-radius: 10px;
                        font-weight: 600;
                        z-index: 1000;
                        animation: slideIn 0.3s ease;
                    `;
                    
                    document.body.appendChild(notification);
                    
                    setTimeout(() => {
                        notification.remove();
                    }, 3000);
                }
            });
        });
    </script>
</body>
</html>